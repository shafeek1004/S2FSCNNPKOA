{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c96c8-d64c-4b3d-9511-5a5b0ad58b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class ChannelSelfAttention(Layer):\n",
    "    def __init__(self):\n",
    "        super(ChannelSelfAttention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name='gamma', shape=[1], initializer='zeros', trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        avg_pool = tf.reduce_mean(x, axis=1, keepdims=True)  \n",
    "        max_pool = tf.reduce_max(x, axis=1, keepdims=True)  \n",
    "        concat = tf.concat([avg_pool, max_pool], axis=1)\n",
    "        attn = tf.nn.sigmoid(concat)\n",
    "        return x * attn * self.gamma\n",
    "\n",
    "def spherical_conv_layer(inputs, filters=16, kernel_size=(3, 3)):\n",
    "     return layers.Conv2D(filters, kernel_size, padding='same', activation='selu')(inputs)\n",
    "\n",
    "def build_s2fscnn(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = spherical_conv_layer(inputs, filters=16, kernel_size=(3, 3))\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = ChannelSelfAttention()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='selu')(x)\n",
    "    x = layers.Dense(64, activation='selu')(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='S2FSCNN')\n",
    "    return model\n",
    "def compile_model(model, learning_rate=0.001):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # PKOA-optimized LR can be set here\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "class CustomMetrics(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.round(self.model.predict(self.validation_data[0]))\n",
    "        y_true = self.validation_data[1]\n",
    "\n",
    "        TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "        FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "\n",
    "        specificity = TN / (TN + FP + 1e-8)\n",
    "        precision = TP / (TP + FP + 1e-8)\n",
    "        recall = TP / (TP + FN + 1e-8)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        error_rate = (FP + FN) / (TP + TN + FP + FN + 1e-8)\n",
    "\n",
    "        print(f\" â€” Specificity: {specificity:.4f}, F1: {f1_score:.4f}, Error Rate: {error_rate:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
